<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation</h1>
            <div class="is-size-4 publication-authors">
              <span class="author-block">
                <a href="https://czzzzh.github.io/">Chuhao Chen</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://frank-zy-dou.github.io/">Zhiyang Dou</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="https://cwchenwang.github.io/">Chen Wang</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://yh2371.github.io/">Yiming Huang</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://chen3110.github.io/">Anjun Chen</a><sup>1,3</sup>,
              </span>
              <span class="author-block">
                <a href="https://fengq1a0.github.io/">Qiao Feng</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://jiataogu.me/">Jiatao Gu</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://lingjie0206.github.io/">Lingjie Liu</a><sup>1</sup>,
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>University of Pennsylvania&nbsp;&nbsp;</span>
              <span class="author-block"><sup>2</sup>The University of Hong Kong&nbsp;&nbsp;</span>
              <span class="author-block"><sup>3</sup>Zhejiang University</span>
            </div>
            
            <div class="column has-text-centered">
              <h2 class="subtitle is-3"><b>CVPR 2025</b></h2>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="./Vid2Sim.pdf" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="./Vid2Sim.mp4"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/CzzzzH/Vid2Sim" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (comming soon)</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div>
        <img src="./static/images/teaser.png" />
        <h2 class="content has-text-justified">
            <b>Vid2Sim</b> achieves high-quality reconstruction of appearance, geometry, and physics from multi-view videos effectively. The
            reconstruction results are simulation-ready, enabling high-fidelity and visually appealing animations via mesh-free simulation. Here, we
            present our methodâ€™s reconstruction and simulation results in the <a href="https://app.gazebosim.org/GoogleResearch/fuel/collections/Scanned%20Objects%20by%20Google%20Research">GSO Dataset</a> .
        </h2>
      </div>
    </div>
  </section>


  <!-- <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-steve">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/steve.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/chair-tp.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-shiba">
            <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/shiba.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-fullbody">
            <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/fullbody.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-blueshirt">
            <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/blueshirt.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-mask">
            <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/mask.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-coffee">
            <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/coffee.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-toby">
            <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/toby2.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section> -->

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered">
        <div class="column">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Faithfully reconstructing textured shapes and physical
properties from videos presents an intriguing yet challenging problem. Significant efforts have been dedicated to advancing such a system identification problem in this area.
Previous methods often rely on heavy optimization pipelines
with a differentiable simulator and renderer to estimate
physical parameters. However, these approaches frequently
necessitate extensive hyperparameter tuning for each scene
and involve a costly optimization process, which limits both
their practicality and generalizability. In this work, we propose a novel framework, Vid2Sim, a generalizable videobased approach for recovering geometry and physical properties through a mesh-free reduced simulation based on
Linear Blend Skinning (LBS), offering high computational
efficiency and versatile representation capability. Specifically, Vid2Sim first reconstructs the observed configuration
of the physical system from video using a feed-forward neural network trained to capture physical world knowledge. A
lightweight optimization pipeline then refines the estimated
appearance, geometry, and physical properties to closely
align with video observations within just a few minutes. Additionally, after the reconstruction, Vid2Sim enables highquality, mesh-free simulation with high efficiency. Extensive experiments demonstrate that our method achieves superior accuracy and efficiency in reconstructing geometry
and physical properties from video data.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <div class="columns is-centered">
        <div class="column">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <video src="./Vid2Sim.mp4" controls loop playsinline height="100%"></video>
          </div>
        </div>
      </div>
      <!--/ Paper video. -->
    </div>
  </section>

  <!-- <section class="section">
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        
        <div class="column">
          <div class="content">
            <h2 class="title is-3">Visual Effects</h2>
            <p>
              Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
              would be impossible without nerfies since it would require going through a wall.
            </p>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/dollyzoom-stacked.mp4" type="video/mp4">
            </video>
          </div>
        </div>

        <div class="column">
          <h2 class="title is-3">Matting</h2>
          <div class="columns is-centered">
            <div class="column content">
              <p>
                As a byproduct of our method, we can also solve the matting problem by ignoring
                samples that fall outside of a bounding box during rendering.
              </p>
              <video id="matting-video" controls playsinline height="100%">
                <source src="./static/videos/matting.mp4" type="video/mp4">
              </video>
            </div>

          </div>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Animation</h2>

          <h3 class="title is-4">Interpolating states</h3>
          <div class="content has-text-justified">
            <p>
              We can also animate the scene by interpolating the deformation latent codes of two input
              frames. Use the slider here to linearly interpolate between the left frame and the right
              frame.
            </p>
          </div>
          <div class="columns is-vcentered interpolation-panel">
            <div class="column is-3 has-text-centered">
              <img src="./static/images/interpolate_start.jpg" class="interpolation-image"
                alt="Interpolate start reference image." />
              <p>Start Frame</p>
            </div>
            <div class="column interpolation-video-column">
              <div id="interpolation-image-wrapper">
                Loading...
              </div>
              <input class="slider is-fullwidth is-large is-info" id="interpolation-slider" step="1" min="0" max="100"
                value="0" type="range">
            </div>
            <div class="column is-3 has-text-centered">
              <img src="./static/images/interpolate_end.jpg" class="interpolation-image"
                alt="Interpolation end reference image." />
              <p class="is-bold">End Frame</p>
            </div>
          </div>
          <br />

          <h3 class="title is-4">Re-rendering the input video</h3>
          <div class="content has-text-justified">
            <p>
              Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
              viewpoint such as a stabilized camera by playing back the training deformations.
            </p>
          </div>
          <div class="content has-text-centered">
            <video id="replay-video" controls muted preload playsinline width="75%">
              <source src="./static/videos/replay.mp4" type="video/mp4">
            </video>
          </div>

        </div>
      </div>


      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Related Links</h2>

          <div class="content has-text-justified">
            <p>
              There's a lot of excellent work that was introduced around the same time as ours.
            </p>
            <p>
              <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an
              idea similar to our windowed position encoding for coarse-to-fine optimization.
            </p>
            <p>
              <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a
                href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
              both use deformation fields to model non-rigid scenes.
            </p>
            <p>
              Some works model videos with a NeRF by directly modulating the density, such as <a
                href="https://video-nerf.github.io/">Video-NeRF</a>, <a
                href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a
                href="https://neural-3d-video.github.io/">DyNeRF</a>
            </p>
            <p>
              There are probably many more by the time you are reading this. Check out <a
                href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a
                href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
            </p>
          </div>
        </div>
      </div>

    </div>
  </section> -->

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{chen2025vid2sim,
        title={Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation},
        author={Chuhao Chen and Zhiyang Dou and Chen Wang and Yiming Huang and Anjun Chen and Qiao Feng and Jiatao Gu and Lingjie Liu},
        journal={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
        year={2025}
      }</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        The website template is sourced from <a href="https://github.com/nerfies/nerfies.github.io"> Nerfies </a>
      </div>
    </div>
  </footer>

</body>

</html>